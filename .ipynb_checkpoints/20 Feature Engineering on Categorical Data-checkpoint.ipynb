{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering on Categorical Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Category or class labels can be text or numeric in nature. Usually there are\n",
    "two types of categorical variables—nominal and ordinal.\n",
    "Nominal categorical features are such that there is no concept of ordering among the values, i.e., it does not make sense to sort or order them. Movie or video game genres, weather seasons, and country names are some examples of nominal attributes. \n",
    "\n",
    "Ordinal categorical variables can be ordered and sorted on the basis of their values and hence these values have specific significance such that their order makes sense. Examples of ordinal attributes include clothing size, education level, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary dependencies and settings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Nominal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name Platform    Year         Genre Publisher\n",
      "1         Super Mario Bros.      NES  1985.0      Platform  Nintendo\n",
      "2            Mario Kart Wii      Wii  2008.0        Racing  Nintendo\n",
      "3         Wii Sports Resort      Wii  2009.0        Sports  Nintendo\n",
      "4  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo\n",
      "5                    Tetris       GB  1989.0        Puzzle  Nintendo\n",
      "6     New Super Mario Bros.       DS  2006.0      Platform  Nintendo\n"
     ]
    }
   ],
   "source": [
    "# Let’s look at a new dataset pertaining to video game sales. \n",
    "# This dataset is also available on Kaggle \n",
    "# (https://www.kaggle.com/gregorut/videogamesales).\n",
    "\n",
    "# # Transforming Nominal Features\n",
    "vg_df = pd.read_csv('datasets_n_images/datasets_module_4/vgsales.csv')\n",
    "print(vg_df[['Name', 'Platform', 'Year', 'Genre', 'Publisher']].iloc[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16598, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The dataset depicted in this dataframe shows us various attributes pertaining to video games. Features like Platform, Genre, and Publisher are nominal categorical variables. Let’s now try to transform the video game Genre feature into a numeric representation. Do note here that this doesn’t indicate that the transformed feature will be a numeric feature. It will still be a discrete valued categorical feature with numbers instead of text for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Action', 1: 'Adventure', 2: 'Fighting', 3: 'Misc', 4: 'Platform', 5: 'Puzzle', 6: 'Racing', 7: 'Role-Playing', 8: 'Shooter', 9: 'Simulation', 10: 'Sports', 11: 'Strategy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "gle = LabelEncoder()\n",
    "genre_labels = gle.fit_transform(vg_df['Genre'])\n",
    "genre_mappings = {index: label for index, label in enumerate(gle.classes_)}\n",
    "print(genre_mappings)\n",
    "\n",
    "# genre_mappings = { index , value }\n",
    "# here index is the labels index i.e 0,1, ..\n",
    "# label in enumerate would fetch all values from gle\n",
    "#gle.classes_ keep a unique copy of all labels with itself and enumerate is used to print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name Platform    Year         Genre  GenreLabel\n",
      "1         Super Mario Bros.      NES  1985.0      Platform           4\n",
      "2            Mario Kart Wii      Wii  2008.0        Racing           6\n",
      "3         Wii Sports Resort      Wii  2009.0        Sports          10\n",
      "4  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing           7\n",
      "5                    Tetris       GB  1989.0        Puzzle           5\n",
      "6     New Super Mario Bros.       DS  2006.0      Platform           4\n"
     ]
    }
   ],
   "source": [
    "# From the output, we can see that a mapping scheme has been generated \n",
    "# where each genre value is mapped to a number with the help of the \n",
    "# LabelEncoder object gle. The transformed labels are stored in the\n",
    "# genre_labels value. Let’s write it back to the original dataframe \n",
    "\n",
    "vg_df['GenreLabel'] = genre_labels\n",
    "print(vg_df[['Name', 'Platform', 'Year', 'Genre', 'GenreLabel']].iloc[1:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Ordinal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gen 1' 'Gen 2' 'Gen 3' 'Gen 4' 'Gen 5' 'Gen 6']\n"
     ]
    }
   ],
   "source": [
    "# Ordinal features are similar to nominal features except that order matters\n",
    "poke_df = pd.read_csv('datasets_n_images/datasets_module_4/Pokemon.csv')\n",
    "poke_df = poke_df.sample(random_state=1, frac=1)#frac=1 means take sample \n",
    "# from 100 percent of the data\n",
    "#the above step is redundant n optional. its only used for shuffling the data\n",
    "\n",
    "print(np.unique(poke_df['Generation']))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# From this output we can see that there are a total of six\n",
    "# generations of Pokémon.\n",
    "\n",
    "This attribute is definitely ordinal because Pokémon belonging to Generation 1\n",
    "were introduced earlier in the video games and the television shows than Generation 2 and so on. Hence they have a sense of order among them. \n",
    "\n",
    "Unfortunately, since there is a specific logic or set of rules involved\n",
    "in case of each ordinal variable, there is no generic module or function to map and transform these features into numeric representations. Hence we need to hand-craft this using our own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name Generation  GenerationLabel\n",
      "242            Octillery      Gen 2                2\n",
      "764           Helioptile      Gen 6                6\n",
      "540               Dialga      Gen 4                4\n",
      "430  DeoxysDefense Forme      Gen 3                3\n",
      "84              Rapidash      Gen 1                1\n",
      "642               Swanna      Gen 5                5\n"
     ]
    }
   ],
   "source": [
    "gen_ord_map = {'Gen 1': 1, 'Gen 2': 2, 'Gen 3': 3, \n",
    "               'Gen 4': 4, 'Gen 5': 5, 'Gen 6': 6}\n",
    "\n",
    "poke_df['GenerationLabel'] = poke_df['Generation'].map(gen_ord_map)\n",
    "print(poke_df[['Name', 'Generation', 'GenerationLabel']].iloc[4:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You might now be wondering we already transformed and mapped the categorical\n",
    "variables into numeric representations in the previous sections so why would we need more levels of encoding again? \n",
    "\n",
    "The answer to this is pretty simple. If we directly fed these transformed numeric representations of categorical features into any algorithm, the model will essentially try to interpret these as raw numeric features and hence the notion of magnitude will be wrongly introduced in the system."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Simple example would be from our previous output dataframe, a model fit on GenerationLabel would think that value 6 > 5 > 4 and so on. While order is important in the case of Pokémon generations (ordinal variable), there is no notion of magnitude here. Generation 6 is not larger than Generation 5 and\n",
    "Generation 1 is not smaller than Generation 6. Hence models built using these features directly would be sub-optimal and incorrect models.\n",
    "\n",
    "Solution : One Hot Encoding Scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name Generation  Legendary\n",
      "242            Octillery      Gen 2      False\n",
      "764           Helioptile      Gen 6      False\n",
      "540               Dialga      Gen 4       True\n",
      "430  DeoxysDefense Forme      Gen 3       True\n",
      "84              Rapidash      Gen 1      False\n",
      "642               Swanna      Gen 5      False\n",
      "-------------------------------------------------------\n",
      "                    Name Generation  Gen 1  Gen 2  Gen 3  Gen 4  Gen 5  Gen 6\n",
      "242            Octillery      Gen 2      0      1      0      0      0      0\n",
      "764           Helioptile      Gen 6      0      0      0      0      0      1\n",
      "540               Dialga      Gen 4      0      0      0      1      0      0\n",
      "430  DeoxysDefense Forme      Gen 3      0      0      1      0      0      0\n",
      "84              Rapidash      Gen 1      1      0      0      0      0      0\n",
      "642               Swanna      Gen 5      0      0      0      0      1      0\n"
     ]
    }
   ],
   "source": [
    "# Considering we have numeric representation of any categorical feature \n",
    "# with m labels, the one hot encoding scheme, encodes or transforms \n",
    "# the feature into m binary features, which can only contain a value of 1 \n",
    "# or 0. Each observation in the categorical feature is thus converted \n",
    "# into a vector of size m with only one of the values as 1 \n",
    "# (indicating it as active). \n",
    "# Let’s take our Pokémon dataset and perform some one hot encoding\n",
    "# transformations on some of its categorical features.\n",
    "\n",
    "print(poke_df[['Name', 'Generation', 'Legendary']].iloc[4:10])\n",
    "print(\"-------------------------------------------------------\")\n",
    "gen_onehot_features = pd.get_dummies(poke_df['Generation'])\n",
    "print(pd.concat([poke_df[['Name', 'Generation']], gen_onehot_features], axis=1).iloc[4:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Hashing Scheme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hashing schemes work on strings, numbers and other structures like vectors. \n",
    "\n",
    "You can think of hashed outputs as a finite set of h bins such that when hash function is applied on the same values, they get assigned to the same bin out of the h bins based on the hash value. We can assign the value of h, which becomes the final size of the encoded feature vector for each categorical feature we encode using the feature hashing scheme. \n",
    "\n",
    "Thus even if we have over 1000 distinct categories in a feature and \n",
    "we set h = 10, the output feature set will still have only 10 features as compared to 1000 features if we used a one hot encoding scheme.\n",
    "\n",
    "Let’s look at the following code snippet, which shows us the number of distinct genres we have in our video game dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total game genres: 12\n",
      "['Action' 'Adventure' 'Fighting' 'Misc' 'Platform' 'Puzzle' 'Racing'\n",
      " 'Role-Playing' 'Shooter' 'Simulation' 'Sports' 'Strategy']\n"
     ]
    }
   ],
   "source": [
    "unique_genres = np.unique(vg_df[['Genre']])\n",
    "print(\"Total game genres:\", len(unique_genres))\n",
    "print(unique_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see from the output that there are 12 distinct genres and if we used a one hot encoding scheme on the Genre feature, we would end up having 12 binary features. Instead, we will now use a feature hashing scheme by leveraging scikit-learn's FeatureHasher class, which uses a signed 32-bit version of the Murmurhash3 hash function. The following code shows us how to use the feature hashing scheme where we will pre-set the feature vector size to be 6 (6 features instead of 12).\n",
    "\n",
    "> https://www.quora.com/Can-you-explain-feature-hashing-in-an-easily-understandable-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name         Genre    0    1    2    3    4    5\n",
      "1         Super Mario Bros.      Platform  0.0  2.0  2.0 -1.0  1.0  0.0\n",
      "2            Mario Kart Wii        Racing -1.0  0.0  0.0  0.0  0.0 -1.0\n",
      "3         Wii Sports Resort        Sports -2.0  2.0  0.0 -2.0  0.0  0.0\n",
      "4  Pokemon Red/Pokemon Blue  Role-Playing -1.0  1.0  2.0  0.0  1.0 -1.0\n",
      "5                    Tetris        Puzzle  0.0  1.0  1.0 -2.0  1.0 -1.0\n",
      "6     New Super Mario Bros.      Platform  0.0  2.0  2.0 -1.0  1.0  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "fh = FeatureHasher(n_features=6, input_type='string')\n",
    "hashed_features = fh.fit_transform(vg_df['Genre'])\n",
    "hashed_features = hashed_features.toarray()#above it was series,\n",
    "# we r converting it to an array\n",
    "print(pd.concat([vg_df[['Name', 'Genre']], \n",
    "                 pd.DataFrame(hashed_features)], axis=1).iloc[1:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does scikit learn's HashingVectorizer give negative values?\n",
    "https://stats.stackexchange.com/questions/237857/why-does-scikit-learns-hashingvectorizer-give-negative-values\n",
    "\n",
    "https://github.com/scikit-learn/scikit-learn/issues/7513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name         Genre    0    1    2    3\n",
      "1         Super Mario Bros.      Platform  2.0  0.0  1.0  1.0\n",
      "2            Mario Kart Wii        Racing -1.0 -1.0  0.0  0.0\n",
      "3         Wii Sports Resort        Sports -1.0  1.0 -1.0 -1.0\n",
      "4  Pokemon Red/Pokemon Blue  Role-Playing  1.0 -2.0  1.0  2.0\n",
      "5                    Tetris        Puzzle  2.0 -3.0  0.0  1.0\n",
      "6     New Super Mario Bros.      Platform  2.0  0.0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "fh = FeatureHasher(n_features=4, input_type='string')\n",
    "hashed_features = fh.fit_transform(vg_df['Genre'])\n",
    "hashed_features = hashed_features.toarray()#above it was series, we r converting it to an array\n",
    "print(pd.concat([vg_df[['Name', 'Genre']], \n",
    "                 pd.DataFrame(hashed_features)], axis=1).iloc[1:7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
